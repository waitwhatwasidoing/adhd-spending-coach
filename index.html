<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Impulse Spending Pause</title>
  <style>
    body {
      font-family: "Inter", sans-serif;
      background: #f9fafb;
      display: flex;
      align-items: center;
      justify-content: center;
      height: 100vh;
      margin: 0;
      padding: 20px;
    }
    .container {
      background: white;
      border-radius: 20px;
      padding: 30px;
      box-shadow: 0 10px 40px rgba(0,0,0,0.08);
      max-width: 500px;
      width: 100%;
    }
    h1 {
      font-size: 22px;
      text-align: center;
      margin-bottom: 10px;
    }
    p {
      text-align: center;
      color: #666;
      margin-bottom: 20px;
    }
    .conversation {
      max-height: 320px;
      overflow-y: auto;
      margin-bottom: 15px;
      padding-right: 10px;
    }
    .message {
      margin-bottom: 12px;
      padding: 10px 14px;
      border-radius: 12px;
      font-size: 15px;
      line-height: 1.4;
    }
    .ai { background: #e6fffa; border-left: 4px solid #38b2ac; }
    .user { background: #fff5f5; border-left: 4px solid #f56565; margin-left: 20px; }
    .status { text-align: center; color: #888; font-size: 14px; margin-bottom: 10px; }
  </style>
</head>
<body>
  <div class="container">
    <h1>🧘 Impulse Pause Coach</h1>
    <p>I’m here to help you pause, breathe, and reflect before spending.</p>
    <div id="conversation" class="conversation"></div>
    <div class="status" id="status">🎤 Listening...</div>
  </div>
<script>
  // ===== Impulse Pause Coach — Always-on Voice (Netlify/HTTPS) =====
  let recognition;
  let isListening = false;
  let voices = [];
  let bestVoice = null;

  const statusEl = document.getElementById('status');
  const convoEl  = document.getElementById('conversation');

  // Restore previous conversation
  const conversationHistory = JSON.parse(localStorage.getItem('impulse_convo') || '[]');
  conversationHistory.forEach(m => render(m.sender, m.text));

  function render(sender, text) {
    const el = document.createElement('div');
    el.className = 'message ' + sender;
    el.textContent = text;
    convoEl.appendChild(el);
    convoEl.scrollTop = convoEl.scrollHeight;
  }
  function remember(sender, text) {
    conversationHistory.push({ sender, text, ts: Date.now() });
    // keep last 200 msgs
    localStorage.setItem('impulse_convo', JSON.stringify(conversationHistory.slice(-200)));
  }

  // -------- Voice selection (pick best available, e.g., Natural/Neural/Siri) --------
  function populateVoices() {
    voices = speechSynthesis.getVoices();
    bestVoice =
      voices.find(v => /Natural|Neural|Siri|Premium/i.test(v.name)) ||
      voices.find(v => /Google US English|Google UK English|Samantha|Alex/i.test(v.name)) ||
      voices[0] || null;
  }
  if ('speechSynthesis' in window) {
    speechSynthesis.onvoiceschanged = populateVoices;
    populateVoices();
  }

  function speak(text) {
    if (!('speechSynthesis' in window)) return;
    // stop any existing speech
    speechSynthesis.cancel();
    const u = new SpeechSynthesisUtterance(text);
    if (bestVoice) { u.voice = bestVoice; u.lang = bestVoice.lang; }
    u.rate = 0.98;
    u.pitch = 1;
    speechSynthesis.speak(u);
  }

  // -------- Always-on mic (auto restarts, no button) --------
  function startRecognition() {
    if (!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window)) {
      statusEl.textContent = '❌ Voice input not supported on this device.';
      return;
    }
    if (isListening) return;

    recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.continuous = true;
    recognition.interimResults = false;
    recognition.lang = 'en-US';

    recognition.onstart = () => { isListening = true; statusEl.textContent = '🎤 Listening...'; };

    // If the user starts making sound/speech → stop TTS immediately (so it “pauses”)
    recognition.onsoundstart = recognition.onspeechstart = () => {
      if (speechSynthesis.speaking) speechSynthesis.cancel();
    };

    recognition.onresult = (e) => {
      const res = e.results[e.results.length - 1];
      if (!res.isFinal) return;
      const transcript = res[0].transcript.trim();
      render('user', transcript);
      remember('user', transcript);

      const reply = coachReply(transcript);
      render('ai', reply);
      remember('ai', reply);
      speak(reply);
    };

    recognition.onerror = (e) => {
      statusEl.textContent = (e.error === 'not-allowed')
        ? '⚠️ Please allow microphone access.'
        : '⚠️ Voice error. Reconnecting...';
    };

    recognition.onend = () => {
      isListening = false;
      // auto-restart to keep it always listening
      setTimeout(() => startRecognition(), 400);
    };

    recognition.start();
  }

  // -------- Friendly ADHD coach logic + checklist nudges --------
  function coachReply(input) {
    const lower = input.toLowerCase();
    const checks = [
      "Do you need this or just want it?",
      "Where will you store it?",
      "Can you wait 24 hours?",
      "How might you feel about it tomorrow?"
    ];

    const price = (input.match(/(?:₹|rs\.?\s*|inr\s*|\$)\s*([0-9][0-9,\.]*)/i) || [])[1];
    const isBuying = /(buy|purchase|order|sale|discount)/i.test(lower);

    if (isBuying) {
      return `Got it — you're considering this. ${checks[0]} ${price ? `It's around ${price}, right? ` : ""}${checks[2]} I can remember this and check back later if you want.`;
    } else {
      const soft = [
        "Take a breath with me. What's pulling you toward this?",
        "I’m here. Is this about excitement, stress, or avoiding something else?",
        "If you didn’t buy it today, what would change for you?"
      ];
      return soft[Math.floor(Math.random() * soft.length)];
    }
  }

  // -------- Boot --------
  const greeting = "👋 Hey, I’m here with you. What’s on your mind today?";
  render('ai', greeting); remember('ai', greeting);
  startRecognition();
</script>

  
</body>
</html>
